# ğŸ¤– Friendly Chatbot

![Made with Flask](https://img.shields.io/badge/Made%20with-Flask-blue)
![Bolt AI](https://img.shields.io/badge/Frontend-Bolt%20AI-yellow)
![LLM](https://img.shields.io/badge/Powered%20By-LLaMA%20%7C%20Together%20AI-brightgreen)
![Open Source](https://img.shields.io/badge/Open%20Source-Yes-blueviolet)

> A simple, intuitive, and fun-to-use AI chatbot built using Bolt AI (Frontend), Flask (Backend), and LLaMA model (API via Together AI). Ideal for anyone looking to understand full-stack LLM chatbot integration!

---

## ğŸŒŸ Demo Preview

![Chatbot Demo](https://media.giphy.com/media/v1.YOUR_CHATBOT_GIF_LINK_HERE/giphy.gif)

---

## ğŸ§  What is this project?

This is a **friendly chatbot** interface that uses:

- **Frontend**: Designed with prompts using **Bolt AI**
- **Backend**: Flask Python server that handles incoming messages
- **LLM Model**: **LLaMA model** via **Together AI API** for generating intelligent responses

It acts like a virtual assistant that replies to your messages based on advanced natural language understanding.

---

## âœ¨ Features

- âœ… AI-Powered Conversations (via LLaMA from Together AI)  
- ğŸŒ Clean & responsive frontend (Bolt AI generated)  
- ğŸ§  Flask backend to handle API calls  
- ğŸš€ Real-time message flow between user and LLM  
- ğŸ” Secure API interaction  

---

## ğŸ“¦ Tech Stack

| Tech       | Usage                                  |
|------------|----------------------------------------|
| ğŸ Python  | Flask backend                          |
| ğŸ“¡ API     | Together AI (LLaMA model)              |
| ğŸ§  AI/LLM   | LLaMA from Together AI                 |
| ğŸ§ª Frontend| Bolt AI (Prompt-Generated UI)          |
| ğŸ“„ JSON    | Message passing structure              |

---

## ğŸ—ï¸ How to Build the Project

> Follow these steps to create your own chatbot from scratch:

### ğŸ”¹ 1. **Design Your Frontend using Bolt AI**
- Go to [https://boltai.app](https://boltai.app)  
- Prompt: _"Create a chat UI for friendly chatbot"_  
- Export the generated HTML/CSS/JS or integrate directly  

### ğŸ”¹ 2. **Set Up Flask Backend**
```bash
mkdir friendly-chatbot
cd friendly-chatbot
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install flask requests

ğŸ”¹ 3. Get API Key from Together AI
Visit: https://together.ai

Sign up and copy your API key

Save it in a .env file:

TOGETHER_API_KEY=your_api_key_here

ğŸ”¹ 4. Connect Frontend â†” Backend
Use fetch() or axios to send user input to your Flask backend

Flask handles the message, calls Together AI API, and returns response

## ğŸ“ Folder Structure

friendly-chatbot/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py # Flask server
â”‚ â”œâ”€â”€ .env # API key file
â”‚ â””â”€â”€ requirements.txt # Python dependencies
â”‚
â”œâ”€â”€ project/ # Bolt AI frontend
â”‚ â””â”€â”€ [prompt-based UI files]
â”‚
â””â”€â”€ README.md

ğŸ§ª Running the Project
ğŸ”¹ 1. Clone the Repo

git clone https://github.com/your-username/friendly-chatbot.git
cd friendly-chatbot

ğŸ”¹ 2. Install Backend Requirements

pip install -r requirements.txt

ğŸ”¹ 3. Create .env File

touch .env
# Add your API key
TOGETHER_API_KEY=your_key

ğŸ”¹ 4. Run the Backend

python app.py

ğŸ”¹ 5. Open the Frontend

Open index.html from the frontend folder in your browser
Or host it using Netlify/Vercel/etc.

ğŸ’¬ Sample API Flow

POST /chat
{
  "message": "Hi there!"
}
Response:
{
  "response": "Hello! How can I assist you today?"
}

ğŸ’¡ Future Improvements

Add user authentication for personalized chat experience

Store chat history in a database

Deploy on platforms like Vercel (Frontend) + Render/Railway (Backend)

ğŸ“¬ Feedback
If you loved it or faced any issues, feel free to raise an issue or DM me!

ğŸ“¢ Final Words
Building this chatbot taught me how frontend, backend, and AI models can work together beautifully.
Enjoy chatting with your virtual friend!

